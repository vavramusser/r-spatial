{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61243b9-b03f-4e2b-ad9e-a00e4fac84de",
   "metadata": {},
   "source": [
    "# Raster Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25d318-c84c-4d84-8c6d-c104696bb07f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This script sources previously downloaded USGS NLCD data and aggregates it by the specified geometry for the specified years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23d28d-b5ed-4fde-b842-1519ae4425ca",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "This notebook includes the following sections:\n",
    "\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448557f0-f009-40b4-8c12-85932717a0c0",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "Before running this script, you will need to install and load the following packages into your R environment:\n",
    "\n",
    "* [**dplyr**](https://cran.r-project.org/web/packages/dplyr)  A package for data manipulation that provides a consistent set of functions to filter, arrange, summarize, and transform data. It makes it easy to work with data frames and perform operations efficiently.\n",
    "\n",
    "* [**exactextractr**](https://cran.r-project.org/web/packages/exactextractr)\n",
    "  \n",
    "* [**ggplot2**](https://cran.r-project.org/web/packages/ggplot2)\n",
    "\n",
    "\n",
    "* [**ipumsr**](https://cran.r-project.org/web/packages/ipumml)  A package specifically designed to interact with IPUMS datasets, including NHGIS. It allows users to define and submit data extraction requests, download data, and read it directly into R for analyss.i\n",
    "\n",
    "* [**sf**](https://cran.r-project.org/web/packages/f)\n",
    "\n",
    "* [**terra**](https://cran.r-project.org/web/packages/terra).\n",
    "\n",
    "To install these packages, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a1e17a-4a1b-4ac9-8231-e15553b77f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into ‘/home/jovyan/R/x86_64-conda-linux-gnu-library/4.3’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Warning message in install.packages(c(\"dplyr\", \"exactextractr\", \"ggplot2\", \"ipumsr\", :\n",
      "“installation of package ‘dplyr’ had non-zero exit status”\n",
      "Warning message in install.packages(c(\"dplyr\", \"exactextractr\", \"ggplot2\", \"ipumsr\", :\n",
      "“installation of package ‘sf’ had non-zero exit status”\n"
     ]
    }
   ],
   "source": [
    "#install.packages(c(\"dplyr\", \"exactextractr\", \"ggplot2\", \"ipumsr\", \"sf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bd84b-32e8-475a-b382-60b2d2970c9d",
   "metadata": {},
   "source": [
    "Once installed, make sure to load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53103a1e-d1e1-4c39-8131-777ea8985e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "The legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\n",
      "which was just loaded, were retired in October 2023.\n",
      "Please refer to R-spatial evolution reports for details, especially\n",
      "https://r-spatial.org/r/2023/05/15/evolution4.html.\n",
      "It may be desirable to make the sf package available;\n",
      "package maintainers should consider adding sf to Suggests:.\n",
      "\n",
      "Linking to GEOS 3.12.0, GDAL 3.7.2, PROJ 9.3.0; sf_use_s2() is TRUE\n",
      "\n",
      "terra 1.7.46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(exactextractr)\n",
    "library(ggplot2)\n",
    "library(ipumsr)\n",
    "library(sf)\n",
    "library(terra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc41707-daf2-4fc0-9389-51014a2e9b97",
   "metadata": {},
   "source": [
    "You will also need to set up an IPUMS account and obtain an IPUMS API key. You can register for an account and get your API key from [the IPUMS website](https://account.ipums.org/api_keys).   The API key will allow you to programmatically interact with the IPUMS NHGIS datasets and extract data based on your specifications.\n",
    "\n",
    "Once you have your IPUMS API key, run the following line of code and enter your key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076b723-ba4d-4084-ad5c-4be8a2e5de21",
   "metadata": {},
   "source": [
    "# Kate's API key\n",
    "## 59cba10d8a5da536fc06b59dd85f877c475a4c7d96dd08a9ce04d9d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bdd8f0f-60ae-44fc-a260-1e79716a3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your IPUMSS API key:  59cba10d8a5da536fc06b59dd85f877c475a4c7d96dd08a9ce04d9d0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing .Renviron file copied to /home/jovyan/.Renviron_backup for backup purposes.\n",
      "\n",
      "The environment variable IPUMS_API_KEY has been set and saved for future sessions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_ipumps_api_key = readline(\"Please enter your IPUMSS API key: \")\n",
    "set_ipums_api_key(my_ipumps_api_key, save = T, overwrite = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88037e5-f278-4fd6-8f11-7e792b40f2cc",
   "metadata": {},
   "source": [
    "## 2. NHGIS Geography Shapefile Exploration and Selection\n",
    "\n",
    "\n",
    "#### Steps:\n",
    "1. Retrieve metadata for available shapefiless.\n",
    "2. Filter and display shapefiles based on years and geographic level.\n",
    "3. Select a shapefile for extration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ea5a9-b4a9-4fd6-9461-1414d6c35293",
   "metadata": {},
   "source": [
    "### 2a. Retrieve Shapefile Metadata¶\r\n",
    "\n",
    "Shapefiles are a type of file format which contain geographic boundaries. This type of file is essential for spatial analysis. This section retrieves and filters shapefile metadata to identify shapefiles which correspond to our selected year and geography. This filtering step ensures you have the correct geographic boundaries foryour projecta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1a9254-7e3e-4de2-ad66-34831521c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_meta <- get_metadata_nhgis(\"shapefiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9baf41c-8452-4c8e-a984-e9d61ec30798",
   "metadata": {},
   "source": [
    "Provides a list of all availible grographic levels iwthin the NHGIS data repository of shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018dc40-b6a8-47d9-96cc-9df752d687ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(shp_meta$geographic_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c3e41-2a3e-4f65-a936-52c695a96842",
   "metadata": {},
   "source": [
    "### 2b. Filter the Shapefiles Based on Year and Geography\n",
    "\n",
    "For this exercise, we will extract a set of shapefiles at your previously-selected geography as well as a specific year.  As we saw in our metadata exploration above, the available geography levels vary based on the dataset.\n",
    "\n",
    "For this filtering step, you should also filter based on the year.  For this exercise, we are using time-series table CL8 which contains information on total population harmonized to 2010 geographies.  Therefore, we should only select a shapefile which corresponds to 2010 geographies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91108058-83b2-40f7-b75a-56bdf246b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_year <- 2022\n",
    "selection_geog <- \"county\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294d9ef-867a-48f8-851f-876ae1439fb3",
   "metadata": {},
   "source": [
    "If you are unfamiliar with Census geographies, it might sound strange to include a year specification in this filtring step.  For large geographies, such as \"nation\" or \"state\", the year is relatively unimportant because the boundaries of these regions are not redrawn from year to year.  However, for smaller geographies, especially those related to the U.S. Decennial Census, such as \"tract\", \"block\" or \"blck_grp\" (block group), and as those related to political districts, such as \"cd\" (congressional district), the boundary of the grography can change over time.  Census tract, block group, and block boundaries are redrawn for each Decennial Census based on population numbers, and Congressional Districts are often redrawn for new congresional elections.  For this reason, it is essential to correspond your shapefile selection to your time-series data extraction.\n",
    "\n",
    "Run the code below to list the available shapefiles based on your year and geography specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60659312-e8e1-4050-bc19-18a5234a2c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 2 × 6\u001b[39m\n",
      "  name                   year  geographic_level   extent        basis   sequence\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m us_county_2022_tl2022  2022  County             United States 2022 T…     \u001b[4m1\u001b[24m870\n",
      "\u001b[90m2\u001b[39m us_cty_sub_2022_tl2022 2022  County Subdivision United States 2022 T…     \u001b[4m1\u001b[24m872\n"
     ]
    }
   ],
   "source": [
    "shp_meta %>% filter(year == selection_year, grepl(selection_geog, geographic_level, ignore.case = T)) %>% print(n = Inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a562a0d-6ba7-4c79-9923-a28c82f392c0",
   "metadata": {},
   "source": [
    "The filtering step provides us with a list of potential shapefiles we can use for our extraction based on the year and geography criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804092e-88b3-4b81-8076-a35171209f69",
   "metadata": {},
   "source": [
    "### 2c. Select a Shapfile\n",
    "\n",
    "For this exercise, we will select the 2010 Census tract dataset based on the 2010 TIGER line files (file \"us_county_2022_tl2022\").  And wee will save this selection for use later in our data extraction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875e5ad2-2d95-4e87-a64d-f2878eb72f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_shp <- \"us_county_2022_tl2022\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05409b43-26d0-448c-83b1-e7f5c3e86dca",
   "metadata": {},
   "source": [
    "## 3. NHGIS Shapefile Extraction Specification and Submission\n",
    "\n",
    "Now that you've identified your dataset and shapefile, this section defines and submits an extraction request to the IPUMS NHGIS API. Extracting data from IPUMS NHGIS allows you to download specific datasets and geographical data directly from the IPUMS server. This method makes it easy to automate and reproduce data requests.  The extraction will include both the selected time-series data and the corresponding shapefiles.\n",
    "\n",
    "#### Steps:\n",
    "1. Define and Run the Data Extraction\n",
    "2. Review the Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2af41-5740-4661-af2c-d2533acecde7",
   "metadata": {},
   "source": [
    "### 3a. Define the Extraction Parameters and Run the Extraction\n",
    "\n",
    "Here we will put everything together including out time series data table selection (selection_datts), our selected geography (selection_geog), and our selected shapefiles (selection_shp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14959af4-9d5f-4d73-8a0a-bcc81800d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction <- define_extract_nhgis(description = \"Geographic Boundaries for NLCD Aggregation\",\n",
    "                                   shapefiles = selection_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33686457-42c4-4cc0-bca4-4f3331cd6b4f",
   "metadata": {},
   "source": [
    "Submit the extraction request and wait for it to complete, then download the resulting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf32e16f-84d9-4da6-bcea-41ad049bfd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully submitted IPUMS NHGIS extract number 81\n",
      "\n",
      "Checking extract status...\n",
      "\n",
      "Waiting 10 seconds...\n",
      "\n",
      "Checking extract status...\n",
      "\n",
      "Waiting 20 seconds...\n",
      "\n",
      "Checking extract status...\n",
      "\n",
      "IPUMS NHGIS extract 81 is ready to download.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'completed'"
      ],
      "text/latex": [
       "'completed'"
      ],
      "text/markdown": [
       "'completed'"
      ],
      "text/plain": [
       "[1] \"completed\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shapefile saved to /home/jovyan/ccdatamining/nhgis0081_shape.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# submit extraction  \n",
    "extraction_submitted <- submit_extract(extraction)\n",
    "\n",
    "# wait for completion\n",
    "extraction_complete <- wait_for_extract(extraction_submitted)\n",
    "\n",
    "# check completion\n",
    "extraction_complete$status\n",
    "\n",
    "# get extraction filepath\n",
    "filepath <- download_extract(extraction_submitted, overwrite = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778d4cd-6b9d-4c6d-a24c-ebf9b62853f7",
   "metadata": {},
   "source": [
    "### 3b. Review the Extracted Files\n",
    "If you followed along with this exercise, your data extraction and download should contain the following two files.  If you expanded your extraction to additional datasets and shapefiles, you extraction will contain additional files.\n",
    "\n",
    "1. A dataset containing total population by Census tract (based on 2010 Census tract boundaries) for all available years in the CL8 time-series dataset (1990, 2000, 2010, and 2020).\n",
    "2. A shapefile with 2010 Census tract boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0d381d-cf44-41cb-89bb-b65413988242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see files in extract\n",
    "shp_raw <- read_ipums_sf(filepath[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a5114-f498-4b7f-9cd0-cce67aef9ac5",
   "metadata": {},
   "source": [
    "### 3c. Subset the Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9a56933-a880-4891-887e-589b66073f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsets the polygon file to only GEOID10 (geography reference code) and geography\n",
    "polygons <- shp_raw[c(\"GISJOIN\", \"GEOID\", \"STATEFP\", \"COUNTYFP\", \"NAME\")]\n",
    "\n",
    "# exclude Alaska (02), Hawaii (15), and Puerto Rico (72) (not covered by the version of the NLCD data we are working with here)\n",
    "polygons <- polygons %>% filter(!STATEFP %in% c(\"02\", \"15\", \"72\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4cf3cc-0bf2-4c81-84a9-7b2a4d01fb27",
   "metadata": {},
   "source": [
    "## 4. Import the NLCD File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7893d93-1a98-4e82-b0ef-8c06a683f684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in new_CppObject_xp(fields$.module, fields$.pointer, ...):\n",
      "“GDAL Error 1: TIFFFetchDirectory:Sanity check on directory count failed, this is probably not a valid IFD offset”\n",
      "Warning message in new_CppObject_xp(fields$.module, fields$.pointer, ...):\n",
      "“GDAL Error 1: TIFFReadDirectory:Failed to read directory at offset 962594904”\n"
     ]
    }
   ],
   "source": [
    "# imports NLCD file from local directory\n",
    "nlcd <- raster(\"/home/jovyan/pipelines/Annual_NLCD_LndCov_2023_CU_C1V0.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8011a7b-0efa-4f70-9868-887191838255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33abc484-e557-4cc6-9a60-27929933ae1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'nlcd' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'nlcd' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "nlcd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
